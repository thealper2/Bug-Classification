{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d1e6bbe-72cb-4cc2-a22e-31c40420e7dc",
   "metadata": {},
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c194c20-0274-4f00-b8bd-7c4756ce64fb",
   "metadata": {},
   "source": [
    "1. Import required libraries\n",
    "2. Load data\n",
    "3. Exploratory data analysis\n",
    "4. Scale data\n",
    "5. Sampling\n",
    "6. Train base models\n",
    "7. Select Features with SelectKBest\n",
    "8. Hyperparameter Tuning with Optuna\n",
    "9. Model Calibration\n",
    "10. Model Explanation with LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af7cf9-0c27-4dd3-8f61-684635dfc85f",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b554827b-b290-48fe-90a5-4f60d7360b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q scikit-plot catboost optuna lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9f4637-eea0-4a47-b8f2-fa00c22a3a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import os\n",
    "import pickle\n",
    "import io\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import lime\n",
    "import shap\n",
    "\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import RobustScaler, OrdinalEncoder, LabelEncoder, label_binarize\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
    "\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "\n",
    "if not os.path.exists(f'./outputs'):\n",
    "    os.makedirs('./outputs')\n",
    "\n",
    "PROJECT_ROOT_DIR = './outputs'\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, 'images')\n",
    "if not os.path.exists(f'./outputs/images'):\n",
    "    os.makedirs('./outputs/images')\n",
    "    \n",
    "def save_fig(title):\n",
    "    path = os.path.join(IMAGES_PATH, title + '.png')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def bold(string):\n",
    "    display(Markdown(\"**\" + string + \"**\"))\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb3d054-9c5d-42cf-833e-501875a5ca34",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fbf68-5c2d-4f95-a739-aa19a96d69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/mnt/d/Datasets/bug_hunter/BugHunterDataset-1.0/single/MapDB/class.csv')\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78049f1-4db8-4ae6-8c7b-457f3d2ac67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(data):\n",
    "    bold(\" SHAPE \".center(50, \"#\"))\n",
    "    print(\"ROWS: {}\".format(data.shape[0]))\n",
    "    print(\"COLUMNS: {}\".format(data.shape[1]))\n",
    "    bold(\" TYPES \".center(50, \"#\"))\n",
    "    print(data.dtypes)\n",
    "    bold(\" MISSING VALUES \".center(50, \"#\"))\n",
    "    print(data.isnull().sum())\n",
    "    bold(\" DUPLICATED VALUES \".center(50, \"#\"))\n",
    "    print(\"NUMBER OF DUPLICATED VALUES: {}\".format(data.duplicated().sum()))\n",
    "    bold(\" MEMORY USAGE \".center(50, \"#\"))\n",
    "    buf = io.StringIO()\n",
    "    data.info(buf=buf)\n",
    "    info = buf.getvalue().split(\"\\n\")[-2].split(\":\")[1].strip()\n",
    "    print(\"Memory Usage: {}\".format(info))\n",
    "    bold(\" DESCRIBE \".center(50, \"#\"))\n",
    "    display(data.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f730f-2957-4416-ac42-c8e25d175dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e670f8-6455-4b56-9ee6-9eca8df190cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_dict = {\n",
    "    'Hash': \"Dosyanın benzersiz bir tanımlayıcısı.\",\n",
    "    'LongName': \"Dosyanın uzun adı.\",\n",
    "    'CC': \"Karmaşıklık Skoru (Cyclomatic Complexity Score).\",\n",
    "    'CCL': \"Karmaşıklık Skoru Limiti (Cyclomatic Complexity Limit).\",\n",
    "    'CCO': \"Karmaşıklık Skoru Aşım Oranı (Cyclomatic Complexity Overflow).\",\n",
    "    'CI': \"Kalite İndeksi.\",\n",
    "    'CLC': \"Kod Kalitesi Limiti.\",\n",
    "    'CLLC': \"Kod Kalitesi Limiti Aşım Oranı.\",\n",
    "    'LDC': \"Lokal Değişken Sayısı (Local Variable Count).\",\n",
    "    'LLDC': \"Lokal Uzunluk Değişken Sayısı (Local Long Variable Count).\",\n",
    "    'LCOM5': \"LCOM5 (Lack of Cohesion in Methods) Metrik Değeri.\",\n",
    "    'NL': \"Nesne Sayısı.\",\n",
    "    'NLE': \"Nesne Limiti.\",\n",
    "    'WMC': \"Ağırlıklı Metot Sayısı (Weighted Method Count).\",\n",
    "    'CBO': \"Bağlılık Sayısı (Coupling Between Objects).\",\n",
    "    'CBOI': \"Bağlılık Sayısı Limiti (Coupling Between Objects Limit).\",\n",
    "    'NII': \"Nesne İçerme İndeksi (Number of Inherited Methods).\",\n",
    "    'NOI': \"Nesne İçerme Limiti (Number of Inherited Limit).\",\n",
    "    'RFC': \"Fonksiyon Çağrısı Sayısı (Response For a Class).\",\n",
    "    'AD': \"Asgari Mesafe.\",\n",
    "    'CD': \"Çocuk Sayısı (Child Count).\",\n",
    "    'CLOC': \"Yürütülen Kod Satırı Sayısı (Count of Lines of Code).\",\n",
    "    'DLOC': \"Silinen Kod Satırı Sayısı (Deleted Lines of Code).\",\n",
    "    'PDA': \"Genel Çeşitlilik.\",\n",
    "    'PUA': \"Kullanılmayan Parametre Sayısı (Unused Parameters Count).\",\n",
    "    'TCD': \"Çalışma Süresi Bağlılığı (Temporal Coupling Degree).\",\n",
    "    'TCLOC': \"Toplam Yürütülen Kod Satırı Sayısı (Total Count of Lines of Code).\",\n",
    "    'DIT': \"Derinlik İkilik Ağacı (Depth of Inheritance Tree).\",\n",
    "    'NOA': \"İlgili Nesne Sayısı (Number of Aggregated Objects).\",\n",
    "    'NOC': \"İlgili Çocuk Nesne Sayısı (Number of Children).\",\n",
    "    'NOD': \"Çıkış Nesnesi Sayısı (Number of Descendants).\",\n",
    "    'NOP': \"Çıkış Parametre Sayısı (Number of Parameters).\",\n",
    "    'LLOC': \"Lokal Kod Satırı Sayısı (Local Lines of Code).\",\n",
    "    'LOC': \"Toplam Kod Satırı Sayısı (Lines of Code).\",\n",
    "    'NA': \"İlgili Metot Sayısı (Number of Attributes).\",\n",
    "    'NG': \"Metot Grup Sayısı (Number of Groups).\",\n",
    "    'NLA': \"Uygulanan Lokal Arayüz Sayısı (Number of Local Accessors).\",\n",
    "    'NLG': \"Uygulanan Lokal Getter Sayısı (Number of Local Getters).\",\n",
    "    'NLM': \"Uygulanan Lokal Metot Sayısı (Number of Local Methods).\",\n",
    "    'NLPA': \"Uygulanan Lokal Parametre Sayısı (Number of Local Parameters).\",\n",
    "    'NLPM': \"Uygulanan Lokal Parametre Metot Sayısı (Number of Local Parameter Methods).\",\n",
    "    'NLS': \"Uygulanan Lokal Setter Sayısı (Number of Local Setters).\",\n",
    "    'NM': \"Uygulanan Metot Sayısı (Number of Methods).\",\n",
    "    'NOS': \"Çıkış Üzerindeki Nesne Sayısı (Number of Objects).\",\n",
    "    'NPA': \"Uygulanan Parametre Sayısı (Number of Parameters).\",\n",
    "    'NPM': \"Uygulanan Parametre Metot Sayısı (Number of Parameter Methods).\",\n",
    "    'NS': \"Uygulanan Setter Sayısı (Number of Setters).\",\n",
    "    'TLLOC': \"Toplam Lokal Kod Satırı Sayısı (Total Lines of Local Code).\",\n",
    "    'TLOC': \"Toplam Kod Satırı Sayısı (Total Lines of Code).\",\n",
    "    'TNA': \"Toplam Nesne Sayısı (Total Number of Objects).\",\n",
    "    'TNG': \"Toplam Metot Grup Sayısı (Total Number of Groups).\",\n",
    "    'TNLA': \"Toplam Uygulanan Lokal Arayüz Sayısı (Total Number of Local Accessors).\",\n",
    "    'TNLG': \"Toplam Uygulanan Lokal Getter Sayısı (Total Number of Local Getters).\",\n",
    "    'TNLM': \"Toplam Uygulanan Lokal Metot Sayısı (Total Number of Local Methods).\",\n",
    "    'TNLPA': \"Toplam Uygulanan Lokal Parametre Sayısı (Total Number of Local Parameters).\",\n",
    "    'TNLPM': \"Toplam Uygulanan Lokal Parametre Metot Sayısı (Total Number of Local Parameter Methods).\",\n",
    "    'TNLS': \"Toplam Uygulanan Lokal Setter Sayısı (Total Number of Local Setters).\",\n",
    "    'TNM': \"Toplam Uygulanan Metot Sayısı (Total Number of Methods).\",\n",
    "    'TNOS': \"Toplam Çıkış Üzerindeki Nesne Sayısı (Total Number of Objects).\",\n",
    "    'TNPA': \"Toplam Uygulanan Parametre Sayısı (Total Number of Parameters).\",\n",
    "    'TNPM': \"Toplam Uygulanan Parametre Metot Sayısı (Total Number of Parameter Methods).\",\n",
    "    'TNS': \"Toplam Uygulanan Setter Sayısı (Total Number of Setters).\",\n",
    "    'WarningBlocker': \"Bloke Edici Uyarı Sayısı.\",\n",
    "    'WarningCritical': \"Kritik Uyarı Sayısı.\",\n",
    "    'WarningInfo': \"Bilgi Uyarısı Sayısı.\",\n",
    "    'WarningMajor': \"Önemli Uyarı Sayısı.\",\n",
    "    'WarningMinor': \"Küçük Uyarı Sayısı.\",\n",
    "    'Android Rules': \"Android uygulama geliştirme ile ilgili kurallar.\",\n",
    "    'Basic Rules': \"Temel kod yazma kuralları.\",\n",
    "    'Brace Rules': \"Süslü parantez kullanım kuralları.\",\n",
    "    'Clone Implementation Rules': \"Klonlanmış kodların uygulama kuralları.\",\n",
    "    'Code Size Rules': \"Kod boyutu ile ilgili kurallar.\",\n",
    "    'Comment Rules': \"Yorum satırları ile ilgili kurallar.\",\n",
    "    'Controversial Rules': \"Tartışmalı kod yazma kuralları.\",\n",
    "    'Coupling Rules': \"Modül bağlantıları ile ilgili kurallar.\",\n",
    "    'Design Rules': \"Yazılım tasarımı ile ilgili kurallar.\",\n",
    "    'Empty Code Rules': \"Boş kod blokları ile ilgili kurallar.\",\n",
    "    'Finalizer Rules': \"Finalizer metotları ile ilgili kurallar.\",\n",
    "    'Import Statement Rules': \"İmport ifadeleri ile ilgili kurallar.\",\n",
    "    'J2EE Rules': \"Java 2 Enterprise Edition ile ilgili kurallar.\",\n",
    "    'JUnit Rules': \"JUnit test kapsamı ile ilgili kurallar.\",\n",
    "    'Jakarta Commons Logging Rules': \"Jakarta Commons Logging kütüphanesi ile ilgili kurallar.\",\n",
    "    'Java Logging Rules': \"Java loglama ile ilgili kurallar.\",\n",
    "    'JavaBean Rules': \"JavaBean uygulama kuralları.\",\n",
    "    'MigratingToJUnit4 Rules': \"JUnit 4'e geçiş kuralları.\",\n",
    "    'Migration Rules': \"Geçiş kuralları.\",\n",
    "    'Migration13 Rules': \"Geçiş versiyon 1.3 kuralları.\",\n",
    "    'Migration14 Rules': \"Geçiş versiyon 1.4 kuralları.\",\n",
    "    'Migration15 Rules': \"Geçiş versiyon 1.5 kuralları.\",\n",
    "    'Naming Rules': \"İsimlendirme kuralları.\",\n",
    "    'Optimization Rules': \"Kod optimizasyonu ile ilgili kurallar.\",\n",
    "    'Security Code Guideline Rules': \"Güvenlik kodu rehberi kuralları.\",\n",
    "    'Strict Exception Rules': \"Katı istisna kuralları.\",\n",
    "    'String and StringBuffer Rules': \"String ve StringBuffer kullanım kuralları.\",\n",
    "    'Type Resolution Rules': \"Tür çözümleme kuralları.\",\n",
    "    'Unnecessary and Unused Code Rules': \"Gereksiz ve kullanılmayan kod kuralları.\",\n",
    "    'Vulnerability Rules': \"Güvenlik açığı ile ilgili kurallar.\",\n",
    "    'Number of Bugs': \"Hata Sayısı.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d15226-5969-4556-acbd-d631f74e96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_df = pd.DataFrame.from_dict(desc_dict, orient='index').reset_index(level=0)\n",
    "desc_df.columns = [\"Feature\", \"Description\"]\n",
    "desc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74c2fd-7d81-49ad-ad25-4441da07f8e9",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c69fd-6306-4148-85a8-72783020409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_cols(df):\n",
    "    cat_cols = [col for col in df.columns if str(df[col].dtypes) in [\"bool\", \"category\", \"object\"]]\n",
    "    bold(f\"Categorical Variables ({len(cat_cols)})\")\n",
    "    print(cat_cols)\n",
    "    \n",
    "    num_cols = [col for col in df.columns if df[col].dtypes in [int, float]]\n",
    "    bold(f\"Numerical Variables ({len(num_cols)})\")\n",
    "    print(num_cols)\n",
    "    \n",
    "    numerical_but_categorical_cols = [col for col in num_cols if df[col].nunique() < 10]\n",
    "    bold(f\"Numerical but Categorical Variables ({len(numerical_but_categorical_cols)})\")\n",
    "    print(numerical_but_categorical_cols)\n",
    "    \n",
    "    categorical_but_cardinal_cols = [col for col in cat_cols if df[col].nunique() > 20]\n",
    "    bold(f\"Categorical but Cardinal Variables ({len(categorical_but_cardinal_cols)})\")\n",
    "    print(categorical_but_cardinal_cols)\n",
    "\n",
    "    same_value_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "    bold(f\"Same Value Variables ({len(same_value_cols)})\")\n",
    "    print(same_value_cols)\n",
    "\n",
    "    for col in same_value_cols:\n",
    "        if col in cat_cols:\n",
    "            cat_cols.remove(col)\n",
    "        elif col in num_cols:\n",
    "            num_cols.remove(col)\n",
    "        \n",
    "    return cat_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab3e9c1-0951-4b22-831f-8e9ecf7b962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables, numerical_variables = grab_cols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d68a6-325d-4cfe-b026-48ebbe5c6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_num(df, columns):\n",
    "    plt.figure(figsize=(len(columns) / 4, len(columns)))\n",
    "    for i, column in enumerate(columns):\n",
    "        plt.subplot(int(len(columns) / 2) + 1, 2, i + 1)\n",
    "        sns.histplot(x=column, data=df, bins=30, kde=True)\n",
    "        plt.axvline(df[column].mean(), color=\"r\", linestyle=\"--\", label=\"Mean\")\n",
    "        plt.axvline(df[column].median(), color=\"g\", linestyle=\"-\", label=\"Median\")\n",
    "        plt.grid()\n",
    "        plt.title(f\"{column} Distribution\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81773c1e-730e-4fb2-b5d4-08b4447849fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num(df, numerical_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d67701-2f40-42d6-8089-5a80095ee4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_heatmap(df: pd.core.frame.DataFrame, title_name: str='Correlation Map') -> None:\n",
    "    corr = df.corr()\n",
    "    fig, axes = plt.subplots(figsize=(df.shape[1], df.shape[1]))\n",
    "    mask = np.zeros_like(corr)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    sns.heatmap(corr, mask=mask, linewidths=.5, cmap='viridis', annot=True, fmt='.2f')\n",
    "    plt.title(title_name)\n",
    "    #plt.savefig('correlation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8dd22-8f88-436e-b285-18442c0e31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_heatmap(df, 'Dataset Correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1eb8c0-a567-4ed6-952a-2cedbaa64f54",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd5b75-9923-42c8-bf65-641d209f8905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    return [RandomForestClassifier(), AdaBoostClassifier(), GradientBoostingClassifier(), DecisionTreeClassifier(), ExtraTreesClassifier(),\n",
    "            LogisticRegression(), SGDClassifier(), XGBClassifier(), LGBMClassifier(verbose=-100), CatBoostClassifier(verbose=0), MLPClassifier(),\n",
    "            GaussianNB(), SVC(), KNeighborsClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a159b3f5-9ae2-4ad5-a711-41500fe22cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_train(df, drop_cols, target):\n",
    "    X = df.drop(drop_cols, axis=1)\n",
    "    X = df.drop(target, axis=1)\n",
    "    y = df[target]\n",
    "\n",
    "    if not os.path.exists(f'./outputs/process'):\n",
    "        os.makedirs('./outputs/process')\n",
    "    \n",
    "    scores_df = pd.DataFrame(columns=[\"Model Name\", \"Selected Features\", \"Parameters\", \"Train Time\", \"Test Time\", \"Train Accuracy\", \"Test Accuracy\", \"F1\", \"Precision\", \"Recall\"])\n",
    "    samplers = [\"No Sampler\",\n",
    "                #SMOTE(random_state=42),\n",
    "                RandomOverSampler(random_state=42),\n",
    "                #ADASYN(random_state=42),\n",
    "                #BorderlineSMOTE(k_neighbors=4, random_state=42)\n",
    "               ]\n",
    "\n",
    "    class_index = {}\n",
    "    for c in np.unique(y):\n",
    "        class_index[c] = np.where(y == c)[0]\n",
    "\n",
    "    min_class_len = min(len(ind) for ind in class_index.values())\n",
    "    test_index = []\n",
    "    for i in class_index.values():\n",
    "        test_index.extend(np.random.choice(i, size=min_class_len // 2, replace=False))\n",
    "\n",
    "    train_index = np.setdiff1d(X.index.values, test_index)\n",
    "    train_index = list(train_index)\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    rs = RobustScaler()\n",
    "    X_train[numerical_variables] = rs.fit_transform(X_train[numerical_variables])\n",
    "    X_test[numerical_variables] = rs.transform(X_test[numerical_variables])\n",
    "    with open('./outputs/process/rs.pkl', 'wb') as f:\n",
    "        pickle.dump(rs, f)\n",
    "    \n",
    "    class_names = df[target].unique().tolist()\n",
    "\n",
    "    for sampler in samplers:\n",
    "        if sampler == \"No Sampler\":\n",
    "            sampler_name = \"No Sampler\"\n",
    "            X_train_resampled, y_train_resampled = X_train, y_train \n",
    "\n",
    "        else:\n",
    "            sampler_name = str(sampler.__class__).split(\".\")[-1].replace(\"'>\", \"\")\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "        #print(Counter(y_train), '=', len(y_train))\n",
    "        #print(Counter(y_test), '=', len(y_test))\n",
    "\n",
    "        models = load_models()\n",
    "        for i, model in enumerate(models):\n",
    "            train_model(i, model, scores_df, X_train_resampled, X_test, y_train_resampled, y_test, class_names, sampler_name)\n",
    "\n",
    "    scores_df.to_csv(f'./outputs/scores.csv')\n",
    "    plot_results(scores_df, f'Base Models Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723bc7b4-3c61-4624-ad2f-059b4cd26412",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d1f52c-1da4-4bb2-9d73-a0f0bdf52890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(i, model, scores_df, X_train, X_test, y_train, y_test, class_names, sampler_name):\n",
    "    if not os.path.exists(f'./outputs/models'):\n",
    "        os.makedirs(f'./outputs/models')\n",
    "    \n",
    "    best_k = 10\n",
    "    best_score = 0\n",
    "\n",
    "    for k in range(10, X_train.shape[1] + 1):\n",
    "        selector = SelectKBest(score_func=f_classif, k=k)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "\n",
    "        selected_model = clone(model)\n",
    "\n",
    "        selected_model.fit(X_train_selected, y_train)\n",
    "        y_pred = selected_model.predict(X_test_selected)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        if accuracy > best_score:\n",
    "            best_score = accuracy\n",
    "            best_k = k\n",
    "\n",
    "    selector = SelectKBest(score_func=f_classif, k=best_k)\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    selected_features = selector.get_feature_names_out()\n",
    "\n",
    "    model_name = str(model.__class__).split(\".\")[-1].replace(\"'>\", \"\").replace(\"Classifier\", \"\")\n",
    "\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "\n",
    "    if model_name == \"LGBM\":\n",
    "        study.optimize(lambda trial: objective_lgbm(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        study.optimize(lambda trial: objective_ada(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"DecisionTree\":\n",
    "        study.optimize(lambda trial: objective_dt(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"ExtraTree\":\n",
    "        study.optimize(lambda trial: objective_et(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"GradientBoosting\":\n",
    "        study.optimize(lambda trial: objective_gb(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"MLP\":\n",
    "        study.optimize(lambda trial: objective_mlp(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"RandomForest\":\n",
    "        study.optimize(lambda trial: objective_rf(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"SGD\":\n",
    "        study.optimize(lambda trial: objective_sgd(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"XGB\":\n",
    "        study.optimize(lambda trial: objective_xgb(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"SVC\":\n",
    "        study.optimize(lambda trial: objective_svc(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    elif model_name == \"KNeighbors\":\n",
    "        study.optimize(lambda trial: objective_knn(trial, X_train, X_test, y_train, y_test), n_trials=25)\n",
    "        best_params = study.best_params\n",
    "    else:\n",
    "        best_params = {}\n",
    "\n",
    "    model = model.set_params(**best_params)\n",
    "\n",
    "    best_calibration_method = None\n",
    "    best_brier = 1\n",
    "    calibration_methods = ['sigmoid', 'isotonic']\n",
    "    for calibration in calibration_methods:\n",
    "        model_calibrate = clone(model)\n",
    "        calibrated_classifier = CalibratedClassifierCV(model_calibrate, method=calibration, cv=None)\n",
    "        calibrated_classifier.fit(X_train, y_train)\n",
    "        if hasattr(calibrated_classifier, 'predict_proba'):\n",
    "            prob_pos = calibrated_classifier.predict_proba(X_test)\n",
    "        else:\n",
    "            prob_pos = calibrated_classifier.decision_function(X_test)\n",
    "            prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())\n",
    "\n",
    "        y_test_binarized = label_binarize(y_test, classes=np.unique(y_test))\n",
    "        brier_scores = [brier_score_loss(y_test_binarized[:, i], prob_pos[:, i]) for i in range(y_test_binarized.shape[1])]\n",
    "        brier = np.mean(brier_scores)\n",
    "        if brier < best_brier:\n",
    "            best_calibration_method = calibration\n",
    "\n",
    "    model_name = f'{model_name} + {sampler_name} + k={best_k} + {best_calibration_method}'\n",
    "    calibrated_model = CalibratedClassifierCV(model, method=best_calibration_method, cv=None)\n",
    "\n",
    "    start = time.time()\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    train_time = end - start\n",
    "\n",
    "    start = time.time()\n",
    "    y_pred = calibrated_model.predict(X_test)\n",
    "    end = time.time()\n",
    "    test_time = end - start\n",
    "\n",
    "    train_pred = calibrated_model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "    bold(f\" {model_name} \".center(100, \"#\"))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(conf_mat=cm, show_absolute=True, show_normed=True, colorbar=True, figsize=(8, 8))\n",
    "    save_fig(f\"{model_name}_confusion_matrix\")\n",
    "    plt.title(model_name)\n",
    "    plt.show()\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print()\n",
    "\n",
    "    bold(\"#\" * 100)\n",
    "\n",
    "    #print(f\"Model: {model_name} | Accuracy: {round(test_acc, 2)}\")\n",
    "\n",
    "    with open(f'./outputs/models/{model_name}.pkl', 'wb') as file:\n",
    "        pickle.dump(calibrated_model, file)\n",
    "    \n",
    "    scores_df.loc[len(scores_df)] = [model_name, selected_features, best_params, train_time, test_time, train_acc, test_acc, f1, precision, recall]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99c6e3-1e61-4aea-90a6-b07727f36584",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205d6a4-d0cc-4310-8080-dc5f8e255974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "        'metric': 'multi_logloss',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
    "    }\n",
    "\n",
    "    model = LGBMClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a10f6-fddd-4000-9801-f462a3a699e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_xgb(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 3,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'verbosity': 0,\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.005, 0.5),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-5, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-5, 10.0),\n",
    "        'min_child_weight': trial.suggest_loguniform('min_child_weight', 1e-5, 10.0),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3194db-3ad0-434f-95c4-ba8953841146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_rf(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.6, 1.0)\n",
    "    }\n",
    "\n",
    "    model = RandomForestClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4a1693-ed61-4d6e-90f6-14d5489c5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_ada(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "    }\n",
    "\n",
    "    model = AdaBoostClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fd9dc-7261-4067-8bfd-e585d974e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gb(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 1.0),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6af2ef-5112-459d-b751-e221ce68c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_dt(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.6, 1.0)\n",
    "    }\n",
    "\n",
    "    model = DecisionTreeClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b3784-4cf6-4f08-9bd7-5de5a3a39f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_et(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.6, 1.0)\n",
    "    }\n",
    "\n",
    "    model = ExtraTreesClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a54ccf-3515-4b01-81aa-551631024c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_sgd(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n",
    "        'loss': trial.suggest_categorical('loss', ['hinge', 'log_loss', 'modified_huber', 'squared_hinge']),\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l1', 'l2', 'elasticnet'])\n",
    "    }\n",
    "\n",
    "    model = SGDClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e9ff3a-6461-4ad7-957a-a582dfb25f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_mlp(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'activation': trial.suggest_categorical('activation', ['identity', 'logistic', 'tanh', 'relu']),\n",
    "        'solver': trial.suggest_categorical('solver', ['lbfgs', 'sgd', 'adam']),\n",
    "        'alpha': trial.suggest_loguniform('alpha', 1e-5, 1e-1),\n",
    "    }\n",
    "\n",
    "    model = MLPClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e05a4a-eb7c-4994-abe7-20e73ebd5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_svc(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'kernel': trial.suggest_categorical('kernel', ['rbf']),\n",
    "        'C': trial.suggest_loguniform('C', 1e-5, 100),\n",
    "        'gamma': trial.suggest_loguniform('gamma', 1e-5, 100),\n",
    "    }\n",
    "\n",
    "    model = SVC(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995aa1be-25a1-4d0e-abd9-34d12d150e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_knn(trial, X_train, X_test, y_train, y_test):\n",
    "    param = {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 1, 30),\n",
    "        'metric': trial.suggest_categorical('metric', ['euclidean', 'manhattan', 'chebyshev']),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
    "    }\n",
    "    model = KNeighborsClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55520e-6453-4f5f-a52e-2217b71f1fd2",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c99c4-bd02-4aef-a0b3-3ad09a1fda08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df, title):\n",
    "    plt.figure(figsize=(10, 50))\n",
    "\n",
    "    plt.subplot(711)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Train Time\", ascending=False), y=\"Model Name\", x=\"Train Time\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Train Time\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(712)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Test Time\", ascending=False), y=\"Model Name\", x=\"Test Time\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Test Time\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(713)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Train Accuracy\", ascending=True), y=\"Model Name\", x=\"Train Accuracy\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Train Accuracy\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(714)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Test Accuracy\", ascending=True), y=\"Model Name\", x=\"Test Accuracy\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Test Accuracy\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(715)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"F1\", ascending=True), y=\"Model Name\", x=\"F1\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / F1\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(716)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Precision\", ascending=True), y=\"Model Name\", x=\"Precision\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Precision\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "    plt.subplot(717)\n",
    "    ax = sns.barplot(data=df.sort_values(by=\"Recall\", ascending=True), y=\"Model Name\", x=\"Recall\", palette='viridis')\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container)\n",
    "    plt.title(\"Model / Recall\")\n",
    "    plt.xlabel(\"\")\n",
    "    save_fig(\"base_results\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae44693-64fe-420d-aae8-4bb6522f46ad",
   "metadata": {},
   "source": [
    "# Run Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c7d4f9-bf1b-475c-95ec-4fcabc66dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = [\"Hash\", \"LongName\", 'WarningBlocker', 'WarningInfo', 'Android Rules', 'Code Size Rules', 'Comment Rules', 'Coupling Rules', \n",
    "             'MigratingToJUnit4 Rules', 'Migration13 Rules', 'Migration14 Rules', 'Migration15 Rules', 'Vulnerability Rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824dc4de-8ad0-48f1-9937-a5000984d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Number of Bugs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be9532-ea7b-43b4-b568-62c1f21cea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_train(df, drop_list, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec5775-27c5-4456-b896-49641f45f072",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b628f6-d0d4-4283-945c-db94eec657df",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_df = pd.read_csv(\"./outputs/scores.csv\", index_col=0)\n",
    "best_scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3ba77-27f1-4fbb-ad8a-1a6dee2eaf8b",
   "metadata": {},
   "source": [
    "# Model Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87619fdb-cbe3-474c-b6af-f246fa9c21ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = pickle.load(open('./outputs/models/SVC + RandomOverSampler + k=10 + isotonic.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d31076f-5455-400f-8b89-26987adc2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x: best_model.predict_proba(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f31a58-309a-4f04-be22-986f1184137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['NG','NLG','NPM','TNG','TNLG','TNLPM','TNPM','Import Statement Rules','Java Logging Rules','Number of Bugs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11b173-7457-4925-ace6-18a8b93787f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(df[features].astype(int).values,\n",
    "                                                   mode='classification',\n",
    "                                                   class_names=df[target].unique().tolist(),\n",
    "                                                   training_labels=df['Number of Bugs'],\n",
    "                                                   feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac31eea-1ca7-4162-9a14-d7442dc80524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_instances(df, features, predict_fn, explainer, idx_arr):\n",
    "    for i in idx_arr:\n",
    "        exp = explainer.explain_instance(df.loc[i, features].astype(int).values, predict_fn, num_features=len(features))\n",
    "        exp.show_in_notebook(show_table=True)\n",
    "        #exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f0a157-c5fa-458d-bd9d-7fbab51c9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_arr = [0, 7, 10, 125, 450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864d388-73b4-4124-8ad7-5a4689041cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_instances(df, features, predict_fn, explainer, idx_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15c40e1-231a-4b32-ae57-1f531349bd9c",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bdf69b-d605-4f48-a371-bbbfdee000ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores_df.drop(columns=['Selected Features', 'Parameters']).sort_values(by='Test Accuracy', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8b333-1662-49e2-9dd0-8777bc778ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
